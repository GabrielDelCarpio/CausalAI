# Report 2 - GABRIEL DEL CARPIO

The paper seeks to analyze the selection of a subset of unknown regressors with greater predictive capacity in a context of high dimensionality, where the number of observations is less than the total repressors, to obtain a more precise regression function and perform inference with the results. . . Indeed, the research question is what is the potential of applying high dimensionality models, that use the l1 penalty (Lasso) and that search for the set with the greatest predictive power within the regressors, in econometrics?

Regarding some weaknesses and strengths in answering the question, we can make certain observations. The l1 penalty method, by allowing the identities of the coefficients of the relevant repressors to be unknown, can be a powerful practical assumption since it is consistent with the reality that researchers face: knowing only a sample of the total population , making knowledge about which variables are the most important and their magnitude on a population basis unrealistic. However, this could not be completely valid in every similar context, as it should be supported with other research that has found the same result using another method that treats high dimensionality other than through this penalty, as in the example mentioned in the paper. of economic growth on the Solow-Swan-Ramsey hypothesis, where the results of the Lasso models are contrasted by the alternatives proposed by Barro and Sala-i-Martin (1995), apparently ad hoc methodologies. If the objective is to verify the usefulness of these sparse methods with l1 penalty in inference, the ideal would be to contrast the results with other proposed models and find similar results. At that point, the inference may be more valuable and novel.

Although Lasso penalty methods can find the coefficients of repressors in a non-parametric (linear) manner, the estimation remains linear in parameters and maintains the essence of standard regressions in the second post-lasso step. Indeed, the paper shows that, faced with common dimensionality problems, estimating with post lasso has a lower bias than some standard proposals and in many cases a lower error when the samples are small or large. Furthermore, for performing inference, the feasible lasso and post lasso estimators can converge asymptotically to minimizing the prediction error (oracle) almost equally, with the post lasso being better in certain cases. This shows that it is possible that the first Lasso estimation is sufficient to perform inference (in the sense of consistency of the estimators), and that a second stage of regression serves in a complementary way to provide better results, which meets the objective of the paper.

In the case of instrumental variables, the authors demonstrate that using Lasso is more powerful than other methodologies in case of dealing with multiple instrumental variables whose signal is unknown, treating the problem of overfitting in the first stage, selecting the most important instruments, and maintaining a smaller bias in the second, when the regression is performed. However, the proposals for the instrumental variables, in the case proposed in the paper, come from the interactions of a few other proposed instruments, which, although it is empirically coherent in the context of analyzing the effect of education on salary, probably It is not under other contexts where a relationship less likely to be inferred is studied. The inference derived from using Lasso in the face of many instrumental variables is possible under the case in which we test a different set of interactions that can be fulfilled in certain cases and not in others, but there is no way of knowing how consistent the relationships found by Lasso are. , except in a very closed, highly controlled research context with a probable lower overall validity.

In general, although the examples proposed by the authors demonstrate very well the usefulness of Lasso to perform inference, they do so mainly under very detailed contexts, under which penalizing overfitting works, but depending a lot on the data we want to analyze. . That is, using the methodology is good when adequate data is found for it, giving a significant contribution to the inference, but showing usefulness under very specific cases, which we see in the different proposals for the level of penalty and the assumptions to find it through simulations.
    
About the contribution of the work carried out by the authors, the paper contributes to the research question by demonstrating that the l1 penalty tools can be used under contexts of partially linear regression functions, where there is a high number of instrumental variables and contrasting their results with other methodological proposals based mainly on the intuition of the researcher prior to Lasso, which gives him power of inference, and meets the authors' objective.
    
A future advance of the research carried out could be the following three points: First, it is necessary to look for alternative ways in which coefficients are not strictly discarded that, although their impact is almost zero, can provide more relevant information to the causal estimation whose contribution is unknown with certainty, since, dealing with inference issues, find coefficients strictly different from zero is a finding that allows us to conjecture better hypotheses, avoiding problems of making type I and II errors. Second, it would be interesting to see how to apply overfitting penalty methods like Lasso to other branches of econometrics, such as time series and panel data, where it is not so dependent on such a closed context, like the examples indicated in the paper. , which are more oriented to microeconometrics. Finally, using this type of models when there is overfitting in small sample sizes is an issue that is, in my opinion, intuitively contrary to the inference assumptions of the classic linear regression model. Although it is useful, it is not understandable to me to make a causal inference from a sample of 100 people with more than 500 regressors even though the paper has demonstrated it.

